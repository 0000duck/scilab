// =============================================================================
// Scilab ( http://www.scilab.org/ ) - This file is part of Scilab
// Copyright (C) ????-2008 - INRIA - Michael Baudin
//
//  This file is distributed under the same license as the Scilab package.
// =============================================================================
utdir = SCI+"/modules/optimization/tests/unit_tests/optimbase"
 utdir  =
 
 SCI/modules/optimization/tests/unit_t 
      ests/optimbase                                                    
 
// Scilab ( http://www.scilab.org/ ) - This file is part of Scilab
 
// Copyright (C) 2008-2009 - INRIA - Michael Baudin
 
//
 
// This file must be used under the terms of the CeCILL.
 
// This source file is licensed as described in the file COPYING, which
 
// you should have received as part of this distribution.  The terms
 
// are also available at
 
// http://www.cecill.info/licences/Licence_CeCILL_V2-en.txt
 
 
 
//
 
// assert_close --
 
//   Returns 1 if the two real matrices computed and expected are close,
 
//   i.e. if the relative distance between computed and expected is lesser than epsilon.
 
// Arguments
 
//   computed, expected : the two matrices to compare
 
//   epsilon : a small number
 
//
 
function flag = assert_close ( computed, expected, epsilon )
  if expected==0.0 then
    shift = norm(computed-expected);
  else
    shift = norm(computed-expected)/norm(expected);
  end
  if shift < epsilon then
    flag = 1;
  else
    flag = 0;
  end
  if flag <> 1 then pause,end
endfunction
 
//
 
// assert_equal --
 
//   Returns 1 if the two real matrices computed and expected are equal.
 
// Arguments
 
//   computed, expected : the two matrices to compare
 
//   epsilon : a small number
 
//
 
function flag = assert_equal ( computed , expected )
  if computed==expected then
    flag = 1;
  else
    flag = 0;
  end
  if flag <> 1 then pause,end
endfunction
 
 
//
 
// Test optimbase_checkbounds method
 
//
 
//
 
opt = optimbase_new ();
 
opt = optimbase_configure ( opt , "-numberofvariables",2);
 
opt = optimbase_configure ( opt , "-verbose",1);
 
// The bounds are consistent
 
opt = optimbase_configure ( opt , "-boundsmin" , [-5.0 -5.0] );
 
opt = optimbase_configure ( opt , "-boundsmax" , [5.0 5.0] );
 
[ opt , isok ] = optimbase_checkbounds ( opt );
 
assert_equal ( isok , %T );
 
// The min bound does not have a consistent size
 
opt = optimbase_configure ( opt , "-boundsmin" , [-5.0 -5.0 10.0] );
 
opt = optimbase_configure ( opt , "-boundsmax" , [5.0 5.0] );
 
[ opt , isok ] = optimbase_checkbounds ( opt );
The number of variables 2 does not match the number of min bounds 3 from [-5 -5 10] 
assert_equal ( isok , %F );
 
// The max bound does not have a consistent size
 
opt = optimbase_configure ( opt , "-boundsmin" , [-5.0 -5.0] );
 
opt = optimbase_configure ( opt , "-boundsmax" , [5.0 5.0 10.0] );
 
[ opt , isok ] = optimbase_checkbounds ( opt );
The number of variables 2 does not match the number of max bounds 3 from [5 5 10] 
assert_equal ( isok , %F );
 
// The bounds are not consistent
 
opt = optimbase_configure ( opt , "-boundsmin" , [5.0 5.0] );
 
opt = optimbase_configure ( opt , "-boundsmax" , [-5.0 -5.0] );
 
[ opt , isok ] = optimbase_checkbounds ( opt );
The max bound -5.000000e+000 for index 1 is lower than the min bound 5.000000e+000. 
assert_equal ( isok , %F );
 
opt = optimbase_destroy(opt);
 
 
 
// Scilab ( http://www.scilab.org/ ) - This file is part of Scilab
 
// Copyright (C) 2008-2009 - INRIA - Michael Baudin
 
//
 
// This file must be used under the terms of the CeCILL.
 
// This source file is licensed as described in the file COPYING, which
 
// you should have received as part of this distribution.  The terms
 
// are also available at
 
// http://www.cecill.info/licences/Licence_CeCILL_V2-en.txt
 
 
 
//
 
// assert_close --
 
//   Returns 1 if the two real matrices computed and expected are close,
 
//   i.e. if the relative distance between computed and expected is lesser than epsilon.
 
// Arguments
 
//   computed, expected : the two matrices to compare
 
//   epsilon : a small number
 
//
 
function flag = assert_close ( computed, expected, epsilon )
  if expected==0.0 then
    shift = norm(computed-expected);
  else
    shift = norm(computed-expected)/norm(expected);
  end
  if shift < epsilon then
    flag = 1;
  else
    flag = 0;
  end
  if flag <> 1 then pause,end
endfunction
 
//
 
// assert_equal --
 
//   Returns 1 if the two real matrices computed and expected are equal.
 
// Arguments
 
//   computed, expected : the two matrices to compare
 
//   epsilon : a small number
 
//
 
function flag = assert_equal ( computed , expected )
  if computed==expected then
    flag = 1;
  else
    flag = 0;
  end
  if flag <> 1 then pause,end
endfunction
 
//
 
// gould.nonconvex --
 
//   The Gould test case with additionnal inequality constraints.
 
// Arguments
 
//    x : the point where to compute the cost
 
//    index : a flag which states what is to compute
 
//    * if index=1, or no index, returns the value of the cost 
 
//      function (default case)
 
//    * if index=2, returns the value of the nonlinear inequality 
 
//      constraints, as a row array
 
//    * if index=3, returns an array which contains
 
//      at index #0, the value of the cost function  
 
//      at index #1 to the end is the list of the values of the nonlinear 
 
//      constraints
 
//  Discussion:
 
//    The problem is to minimize a cost function with 4 non linear constraints.
 
//    This is Problem 4.1 in Subrahmanyam, extracted from Gould.
 
//    Non convex.
 
//    The constraint region is a narrow winding (half-moon shaped) valley.
 
//    Solution showed with tolerance 1.e-8.
 
//
 
//  Reference:
 
//    An extension of the simplex method to constrained
 
//    nonlinear optimization
 
//    M.B. Subrahmanyam
 
//    Journal of optimization theory and applications
 
//    Vol. 62, August 1989
 
//
 
//    Gould F.J.
 
//    Nonlinear Tolerance Programming
 
//    Numerical methods for Nonlinear optimization
 
//    Edited by F.A. Lootsma, pp 349-366, 1972
 
//
 
function result = gouldnonconvex ( x , index )
  if (~isdef('index','local')) then
    index = 1
  end
  if ( index==1 | index==3 ) then
    f = (x(1) - 10.0 )^3 + ( x(2) - 20.0 ) ^ 3
  end
  if ( index==2 | index==3 ) then
    c1 = x(1) - 13.0
    c2 = ( x(1) - 5.0 )^2  + (x(2) - 5.0 )^2 - 100.0
    c3 = -( x(1) - 6.0 )^2 - (x(2) - 5.0 )^2 + 82.81
    c4 = x(2)
  end
  select index
  case 1 then
      result = f
      mprintf( "Computed f = %e\n", f);
  case 2
      result = [c1 c2 c3 c4]
      mprintf( "Computed constraints = %e %e %e %e\n", c1 , c2 , c3 , c4);
  case 3
      result = [f c1 c2 c3 c4]
      mprintf( "Computed f = %e and constraints = %e %e %e %e\n", f , c1 , c2 , c3 , c4);
  else
    errmsg = sprintf("Unknown index %d", index )
    error(errmsg)
  end
endfunction
 
//
 
// Test optimbase_checkx0 method
 
//
 
// Test without anything
 
opt = optimbase_new ();
 
opt = optimbase_configure ( opt , "-numberofvariables",2);
 
opt = optimbase_configure ( opt , "-verbose",1);
 
[ opt , isok ] = optimbase_checkx0 ( opt );
Checking initial guess...

... initial guess is feasible.

 
assert_equal ( isok , %T );
 
opt = optimbase_destroy(opt);
 
//
 
// Test with satisfied/unsatisfied bounds constraints
 
opt = optimbase_new ();
 
opt = optimbase_configure ( opt , "-numberofvariables",2);
 
opt = optimbase_configure ( opt , "-verbose",1);
 
opt = optimbase_configure ( opt , "-boundsmin" , [-5.0 -5.0] );
 
opt = optimbase_configure ( opt , "-boundsmax" , [5.0 5.0] );
 
opt = optimbase_configure ( opt , "-x0", [1.0 1.0]' );
 
[ opt , isok ] = optimbase_checkx0 ( opt );
Checking initial guess...

... initial guess is feasible.

 
assert_equal ( isok , %T );
 
opt = optimbase_configure ( opt , "-x0",[-6.0 1.0]');
 
[ opt , isok ] = optimbase_checkx0 ( opt );
Checking initial guess...

Component #1/2 of x is lower than min bound -5.000000e+000

... initial guess is not feasible.

 
assert_equal ( isok , %F );
 
opt = optimbase_destroy(opt);
 
//
 
// Test with satisfied/unsatisfied nonlinear inequality constraints
 
opt = optimbase_new ();
 
opt = optimbase_configure ( opt , "-numberofvariables",2);
 
opt = optimbase_configure ( opt , "-verbose",1);
 
opt = optimbase_configure ( opt , "-nbineqconst",4);
 
opt = optimbase_configure ( opt , "-function" , gouldnonconvex );
 
opt = optimbase_configure ( opt , "-x0" , [ 14.0950013 , 0.8429636 ]');
 
[ opt , isok ] = optimbase_checkx0 ( opt );
Checking initial guess...

Computed constraints = 1.095001e+000 2.779266e-007 2.322073e-006 8.429636e-001

Function Evaluation #1 is [1.0950013 0.0000003 0.0000023 0.8429636] at [14.095001 0.8429636]

... initial guess is feasible.

 
assert_equal ( isok , %T );
 
opt = optimbase_configure ( opt , "-x0" , [ 14.0950013 , 0.0 ]');
 
[ opt , isok ] = optimbase_checkx0 ( opt );
Checking initial guess...

Computed constraints = 1.095001e+000 7.719049e+000 -7.719046e+000 0.000000e+000

Function Evaluation #1 is [1.0950013 7.7190486 -7.719046 0] at [14.095001 0]

Inequality constraint #3/4 is not satisfied for x

... initial guess is not feasible.

 
assert_equal ( isok , %F );
 
opt = optimbase_destroy(opt);
 
 
 
// Scilab ( http://www.scilab.org/ ) - This file is part of Scilab
 
// Copyright (C) 2008-2009 - INRIA - Michael Baudin
 
//
 
// This file must be used under the terms of the CeCILL.
 
// This source file is licensed as described in the file COPYING, which
 
// you should have received as part of this distribution.  The terms
 
// are also available at
 
// http://www.cecill.info/licences/Licence_CeCILL_V2-en.txt
 
 
 
//
 
// assert_close --
 
//   Returns 1 if the two real matrices computed and expected are close,
 
//   i.e. if the relative distance between computed and expected is lesser than epsilon.
 
// Arguments
 
//   computed, expected : the two matrices to compare
 
//   epsilon : a small number
 
//
 
function flag = assert_close ( computed, expected, epsilon )
  if expected==0.0 then
    shift = norm(computed-expected);
  else
    shift = norm(computed-expected)/norm(expected);
  end
  if shift < epsilon then
    flag = 1;
  else
    flag = 0;
  end
  if flag <> 1 then pause,end
endfunction
 
//
 
// assert_equal --
 
//   Returns 1 if the two real matrices computed and expected are equal.
 
// Arguments
 
//   computed, expected : the two matrices to compare
 
//   epsilon : a small number
 
//
 
function flag = assert_equal ( computed , expected )
  if computed==expected then
    flag = 1;
  else
    flag = 0;
  end
  if flag <> 1 then pause,end
endfunction
 
//
 
// Test hasbounds method
 
//
 
// Case where there is no bound
 
opt = optimbase_new ();
 
[ opt , hasbounds ] = optimbase_hasbounds ( opt );
 
assert_equal ( hasbounds , %F );
 
opt = optimbase_destroy( opt );
 
// Case where there are bounds
 
opt = optimbase_new ();
 
opt = optimbase_configure(opt,"-numberofvariables",2);
 
opt = optimbase_configure ( opt , "-boundsmin" , [-5.0 -5.0] );
 
opt = optimbase_configure ( opt , "-boundsmax" , [5.0 5.0] );
 
[ opt , hasbounds ] = optimbase_hasbounds ( opt );
 
assert_equal ( hasbounds , %T );
 
opt = optimbase_destroy(opt);
 
 
 
// Scilab ( http://www.scilab.org/ ) - This file is part of Scilab
 
// Copyright (C) 2008-2009 - INRIA - Michael Baudin
 
//
 
// This file must be used under the terms of the CeCILL.
 
// This source file is licensed as described in the file COPYING, which
 
// you should have received as part of this distribution.  The terms
 
// are also available at
 
// http://www.cecill.info/licences/Licence_CeCILL_V2-en.txt
 
 
 
//
 
// assert_close --
 
//   Returns 1 if the two real matrices computed and expected are close,
 
//   i.e. if the relative distance between computed and expected is lesser than epsilon.
 
// Arguments
 
//   computed, expected : the two matrices to compare
 
//   epsilon : a small number
 
//
 
function flag = assert_close ( computed, expected, epsilon )
  if expected==0.0 then
    shift = norm(computed-expected);
  else
    shift = norm(computed-expected)/norm(expected);
  end
  if shift < epsilon then
    flag = 1;
  else
    flag = 0;
  end
  if flag <> 1 then pause,end
endfunction
 
//
 
// assert_equal --
 
//   Returns 1 if the two real matrices computed and expected are equal.
 
// Arguments
 
//   computed, expected : the two matrices to compare
 
//   epsilon : a small number
 
//
 
function flag = assert_equal ( computed , expected )
  if computed==expected then
    flag = 1;
  else
    flag = 0;
  end
  if flag <> 1 then pause,end
endfunction
 
//
 
// gould.nonconvex --
 
//   The Gould test case with additionnal inequality constraints.
 
// Arguments
 
//    x : the point where to compute the cost
 
//    index : a flag which states what is to compute
 
//    * if index=1, or no index, returns the value of the cost 
 
//      function (default case)
 
//    * if index=2, returns the value of the nonlinear inequality 
 
//      constraints, as a row array
 
//    * if index=3, returns an array which contains
 
//      at index #1, the value of the cost function  
 
//      at index #2 to the end is the list of the values of the nonlinear 
 
//      inequality constraints
 
//  Discussion:
 
//    The problem is to minimize a cost function with 4 non linear constraints.
 
//    This is Problem 4.1 in Subrahmanyam, extracted from Gould.
 
//    Non convex.
 
//    The constraint region is a narrow winding (half-moon shaped) valley.
 
//    Solution showed with tolerance 1.e-8.
 
//
 
//  Reference:
 
//    An extension of the simplex method to constrained
 
//    nonlinear optimization
 
//    M.B. Subrahmanyam
 
//    Journal of optimization theory and applications
 
//    Vol. 62, August 1989
 
//
 
//    Gould F.J.
 
//    Nonlinear Tolerance Programming
 
//    Numerical methods for Nonlinear optimization
 
//    Edited by F.A. Lootsma, pp 349-366, 1972
 
//
 
function result = gouldnonconvex ( x , index )
  if (~isdef('index','local')) then
    index = 1
  end
  if ( index==1 | index==3 ) then
    f = (x(1) - 10.0 )^3 + ( x(2) - 20.0 ) ^ 3
  end
  if ( index==2 | index==3 ) then
    c1 = x(1) - 13.0
    c2 = ( x(1) - 5.0 )^2  + (x(2) - 5.0 )^2 - 100.0
    c3 = -( x(1) - 6.0 )^2 - (x(2) - 5.0 )^2 + 82.81
    c4 = x(2)
  end
  select index
  case 1 then
      result = f
      mprintf( "Computed f = %e\n", f);
  case 2
      result = [c1 c2 c3 c4]
      mprintf( "Computed constraints = %e %e %e %e\n", c1 , c2 , c3 , c4);
  case 3
      result = [f c1 c2 c3 c4]
      mprintf( "Computed f = %e and constraints = %e %e %e %e\n", f , c1 , c2 , c3 , c4);
  else
    errmsg = sprintf("Unknown index %d", index )
    error(errmsg)
  end
endfunction
 
//
 
// The same cost function as before, with an 
 
// additionnal argument, which contains parameters of the 
 
// cost function and constraints.
 
// In this case, the mydata variable is passed
 
// explicitely by the optimization class.
 
// So the actual name "mydata" does not matter
 
// and whatever variable name can be used.
 
//
 
function result = gouldnonconvex2 ( x , index , mydata )
  if (~isdef('index','local')) then
    index = 1
  end
  if ( index==1 | index==3 ) then
    f = (x(1) - mydata.f1 )^3 + ( x(2) - mydata.f2 ) ^ 3
  end
  if ( index==2 | index==3 ) then
    c1 = x(1) - mydata.a1
    c2 = ( x(1) - 5.0 )^2  + (x(2) - 5.0 )^2 - mydata.a2
    c3 = -( x(1) - 6.0 )^2 - (x(2) - 5.0 )^2 + mydata.a3
    c4 = x(2)
  end
  select index
  case 1 then
      result = f
      mprintf( "Computed f = %e\n", f);
  case 2
      result = [c1 c2 c3 c4]
      mprintf( "Computed constraints = %e %e %e %e\n", c1 , c2 , c3 , c4);
  case 3
      result = [f c1 c2 c3 c4]
      mprintf( "Computed f = %e and constraints = %e %e %e %e\n", f , c1 , c2 , c3 , c4);
  else
    errmsg = sprintf("Unknown index %d", index )
    error(errmsg)
  end
endfunction
 
//
 
// Test optimbase_isfeasible method
 
//
 
// Test with bounds
 
opt = optimbase_new ();
 
opt = optimbase_configure(opt,"-numberofvariables",2);
 
opt = optimbase_configure(opt,"-verbose",1);
 
opt = optimbase_configure ( opt , "-boundsmin" , [-5.0 -5.0] );
 
opt = optimbase_configure ( opt , "-boundsmax" , [5.0 5.0] );
 
[ opt , isfeasible ] = optimbase_isfeasible ( opt ,  [0.0 0.0] );
 
assert_equal ( isfeasible , 1 );
 
[ opt , isfeasible ] = optimbase_isfeasible ( opt ,  [-6.0 0.0] );
Component #1/2 of x is lower than min bound -5.000000e+000

 
assert_equal ( isfeasible , 0 );
 
[ opt , isfeasible ] = optimbase_isfeasible ( opt ,  [0.0 6.0] );
Component #2/2 of x is greater than max bound 5.000000e+000

 
assert_equal ( isfeasible , 0 );
 
opt = optimbase_destroy(opt);
 
//
 
// Test with nonlinear inequality constraints
 
opt = optimbase_new ();
 
opt = optimbase_configure(opt,"-numberofvariables",2);
 
opt = optimbase_configure(opt,"-verbose",1);
 
opt = optimbase_configure(opt,"-nbineqconst",4);
 
opt = optimbase_configure ( opt , "-function" , gouldnonconvex );
 
[ opt , isfeasible ] = optimbase_isfeasible ( opt ,  [ 14.0950013 , 0.8429636 ] );
Computed constraints = 1.095001e+000 2.779266e-007 2.322073e-006 8.429636e-001

Function Evaluation #1 is [1.0950013 0.0000003 0.0000023 0.8429636] at [14.095001 0.8429636]

 
assert_equal ( isfeasible , 1 );
 
[ opt , isfeasible ] = optimbase_isfeasible ( opt ,  [ 14.0950013 , 0.0 ] );
Computed constraints = 1.095001e+000 7.719049e+000 -7.719046e+000 0.000000e+000

Function Evaluation #2 is [1.0950013 7.7190486 -7.719046 0] at [14.095001 0]

Inequality constraint #3/4 is not satisfied for x

 
assert_equal ( isfeasible , -1 );
 
opt = optimbase_destroy(opt);
 
//
 
// Test with nonlinear inequality constraints and additionnal argument in cost function
 
mystuff = struct()
 mystuff  =
 
0x0 struct array with fields:
 
mystuff.f1 = 10.0
 mystuff  =
 
   f1: 10
 
mystuff.f2 = 20.0
 mystuff  =
 
   f1: 10
   f2: 20
 
mystuff.a1 = 13.0
 mystuff  =
 
   f1: 10
   f2: 20
   a1: 13
 
mystuff.a2 = 100.0
 mystuff  =
 
   f1: 10
   f2: 20
   a1: 13
   a2: 100
 
mystuff.a3 = 82.81
 mystuff  =
 
   f1: 10
   f2: 20
   a1: 13
   a2: 100
   a3: 82.81
 
opt = optimbase_new ();
 
opt = optimbase_configure ( opt , "-numberofvariables",2);
 
opt = optimbase_configure ( opt , "-verbose",1);
 
opt = optimbase_configure ( opt , "-nbineqconst",4);
 
opt = optimbase_configure ( opt , "-function" , gouldnonconvex2 );
 
opt = optimbase_configure ( opt , "-costfargument" , mystuff );
 
[ opt , isfeasible ] = optimbase_isfeasible ( opt ,  [ 14.0950013 , 0.8429636 ] );
Computed constraints = 1.095001e+000 2.779266e-007 2.322073e-006 8.429636e-001

Function Evaluation #1 is [1.0950013 0.0000003 0.0000023 0.8429636] at [14.095001 0.8429636]

 
assert_equal ( isfeasible , 1 );
 
[ opt , isfeasible ] = optimbase_isfeasible ( opt ,  [ 14.0950013 , 0.0 ] );
Computed constraints = 1.095001e+000 7.719049e+000 -7.719046e+000 0.000000e+000

Function Evaluation #2 is [1.0950013 7.7190486 -7.719046 0] at [14.095001 0]

Inequality constraint #3/4 is not satisfied for x

 
assert_equal ( isfeasible , -1 );
 
opt = optimbase_destroy(opt);
 
 
 
// Scilab ( http://www.scilab.org/ ) - This file is part of Scilab
 
// Copyright (C) 2008-2009 - INRIA - Michael Baudin
 
//
 
// This file must be used under the terms of the CeCILL.
 
// This source file is licensed as described in the file COPYING, which
 
// you should have received as part of this distribution.  The terms
 
// are also available at
 
// http://www.cecill.info/licences/Licence_CeCILL_V2-en.txt
 
 
 
//
 
// assert_close --
 
//   Returns 1 if the two real matrices computed and expected are close,
 
//   i.e. if the relative distance between computed and expected is lesser than epsilon.
 
// Arguments
 
//   computed, expected : the two matrices to compare
 
//   epsilon : a small number
 
//
 
function flag = assert_close ( computed, expected, epsilon )
  if expected==0.0 then
    shift = norm(computed-expected);
  else
    shift = norm(computed-expected)/norm(expected);
  end
  if shift < epsilon then
    flag = 1;
  else
    flag = 0;
  end
  if flag <> 1 then pause,end
endfunction
 
//
 
// assert_equal --
 
//   Returns 1 if the two real matrices computed and expected are equal.
 
// Arguments
 
//   computed, expected : the two matrices to compare
 
//   epsilon : a small number
 
//
 
function flag = assert_equal ( computed , expected )
  if computed==expected then
    flag = 1;
  else
    flag = 0;
  end
  if flag <> 1 then pause,end
endfunction
 
function y = rosenbrock (x)
  y = 100*(x(2)-x(1)^2)^2 + (1-x(1))^2;
endfunction
 
 
//
 
// myoutputcmd --
 
//  This command is called back by the Optimization 
 
//  algorithm.
 
// Arguments
 
//  state : the current state of the algorithm
 
//    "init", "iter", "done"
 
//  data : the data at the current state
 
//    This is a tlist with the following entries:
 
//    * x : the optimal vector of parameters
 
//    * fval : the minimum function value
 
//    * iteration : the number of iterations performed
 
//    * funccount : the number of function evaluations
 
//
 
function myoutputcmd ( state , data )
  global _OUTPUCMDFLAG_
  // Unload the array, just to make sure that the minimum is there
  iter = data.iteration
  fc = data.funccount
  fval = data.fval
  x = data.x
  _OUTPUCMDFLAG_ = 1
endfunction
 
 
global _OUTPUCMDFLAG_
 
_OUTPUCMDFLAG_ = 0
 _OUTPUCMDFLAG_  =
 
    0.  
 
 
//
 
// myoutputcmd2 --
 
//  This command is called back by the Optimization 
 
//  algorithm.
 
// Arguments
 
//  state : the current state of the algorithm
 
//    "init", "iter", "done"
 
//  data : the data at the current state
 
//    This is a tlist with the following entries:
 
//    * x : the optimal vector of parameters
 
//    * fval : the minimum function value
 
//    * iteration : the number of iterations performed
 
//    * funccount : the number of function evaluations
 
//  myobj : a user-defined data structure
 
//
 
function myoutputcmd2 ( state , data , myobj )
  global _OUTPUCMDFLAG_
  // Unload the array, just to make sure that the minimum is there
  iter = data.iteration
  fc   = data.funccount
  fval = data.fval
  x    = data.x
  _OUTPUCMDFLAG_ = myobj.myarg
endfunction
 
 
 
global _OUTPUCMDFLAG_
 
_OUTPUCMDFLAG_ = 0
 _OUTPUCMDFLAG_  =
 
    0.  
 
 
myobj = tlist(["T_MYSTUFF","myarg"]);
 
myobj.myarg = 12;
 
 
//
 
// In this case, the mydata variable is passed
 
// explicitely by the optimization class.
 
// So the actual name "mydata" does not matter
 
// and whatever variable name can be used.
 
//
 
function y = rosenbrock2 ( x , mydata )
  a = mydata.a
  y = 100*(x(2)-x(1)^2)^2 + ( a - x(1))^2;
endfunction
 
 
//
 
// Test with an additional argument
 
//
 
mystuff = tlist(["T_MYSTUFF","a"]);
 
mystuff.a = 12.0;
 
 
//
 
// Test nearly all features of the optimization "abstract" class
 
//
 
 
opt = optimbase_new ();
 
// Check number of variables
 
opt = optimbase_configure(opt,"-numberofvariables",2);
 
nbvar = optimbase_cget(opt,"-numberofvariables");
 
assert_equal ( nbvar , 2 );
 
// Check cost function without additionnal argument
 
opt = optimbase_configure(opt,"-function",rosenbrock);
 
[this,f] = optimbase_function ( opt , [0.0 0.0] );
 
assert_close ( f , 1.0 , %eps );
 
// Check cost function with additionnal argument
 
opt = optimbase_configure(opt,"-function",rosenbrock2);
 
opt = optimbase_configure(opt,"-costfargument",mystuff);
 
[this,f] = optimbase_function ( opt , [0.0 0.0] );
 
assert_close ( f , 144.0 , %eps );
 
// Check initial guess
 
opt = optimbase_configure(opt,"-x0",[-1.2 1.0]');
 
x0 = optimbase_cget(opt,"-x0");
 
assert_close ( x0 , [-1.2 1.0]' , %eps);
 
// Check maxiter
 
opt = optimbase_configure(opt,"-maxiter",200);
 
maxiter = optimbase_cget(opt,"-maxiter");
 
assert_equal ( maxiter , 200);
 
// Check maxfunevals
 
opt = optimbase_configure(opt,"-maxfunevals",200);
 
maxfunevals = optimbase_cget(opt,"-maxfunevals");
 
assert_equal ( maxfunevals , 200);
 
// Check tolfunrelative
 
opt = optimbase_configure(opt,"-tolfunrelative",10*%eps);
 
tolfunrelative = optimbase_cget(opt,"-tolfunrelative");
 
assert_equal ( tolfunrelative , 10*%eps );
 
// Check tolxrelative
 
opt = optimbase_configure(opt,"-tolxrelative",10*%eps);
 
tolxrelative = optimbase_cget(opt,"-tolxrelative");
 
assert_equal ( tolxrelative , 10*%eps );
 
// Check verbose
 
opt = optimbase_configure(opt,"-verbose",1);
 
verbose = optimbase_cget(opt,"-verbose");
 
assert_equal ( verbose , 1 );
 
opt = optimbase_configure(opt,"-verbose",0);
 
// Check verbose termination
 
opt = optimbase_configure(opt,"-verbosetermination",1);
 
verbosetermination = optimbase_cget(opt,"-verbosetermination");
 
assert_equal ( verbosetermination , 1 );
 
opt = optimbase_configure(opt,"-verbosetermination",0);
 
// Check optimum
 
opt = optimbase_set(opt,"-xopt",[1.0 1.0]);
 
xopt = optimbase_get(opt,"-xopt");
 
assert_close ( xopt , [1.0 1.0], %eps );
 
// Check function value at optimum
 
opt = optimbase_set(opt,"-fopt",1.0);
 
fopt = optimbase_get(opt,"-fopt");
 
assert_close ( fopt , 1.0 , %eps );
 
// Check status
 
opt = optimbase_set(opt,"-status","maxiter");
 
status = optimbase_get(opt,"-status");
 
assert_equal ( status , "maxiter" );
 
// Log a message
 
opt = optimbase_configure(opt,"-verbose",1);
 
opt = optimbase_log ( opt , "My interesting message" );
My interesting message

 
opt = optimbase_configure(opt,"-verbose",0);
 
// Log a message relative to the stopping rule
 
opt = optimbase_configure(opt,"-verbosetermination",1);
 
opt = optimbase_stoplog ( opt , "My interesting stop message" );
 
opt = optimbase_configure(opt,"-verbosetermination",0);
 
// Check output command without additionnal argument
 
opt = optimbase_configure(opt,"-outputcommand",myoutputcmd);
 
brutedata = optimbase_outstruct ( opt );
 
mydata = tlist(["T_MYDATA",...
      "x","fval","iteration","funccount",...
      "myspecialdata"]);
 
mydata.x = brutedata.x;
 
mydata.fval = brutedata.fval;
 
mydata.iteration = brutedata.iteration;
 
mydata.funccount = brutedata.funccount;
 
mydata.myspecialdata = "yahoo !";
 
optimbase_outputcmd ( opt , "init" , mydata );
 
assert_equal ( _OUTPUCMDFLAG_ , 1 );
 
// Check output command with additionnal argument
 
opt = optimbase_configure(opt,"-outputcommand",myoutputcmd2);
 
opt = optimbase_configure(opt,"-outputcommandarg",myobj);
 
brutedata = optimbase_outstruct ( opt );
 
mydata = tlist(["T_MYDATA",...
      "x","fval","iteration","funccount",...
      "myspecialdata"]);
 
mydata.x = brutedata.x;
 
mydata.fval = brutedata.fval;
 
mydata.iteration = brutedata.iteration;
 
mydata.funccount = brutedata.funccount;
 
mydata.myspecialdata = "yahoo !";
 
optimbase_outputcmd ( opt , "init" , mydata );
 
assert_equal ( _OUTPUCMDFLAG_ , 12. );
 
// Check incriter
 
opt = optimbase_incriter ( opt );
 
iter = optimbase_get ( opt , "-iterations");
 
assert_equal ( iter , 1 );
 
// Check history storing with xopt
 
opt = optimbase_configure ( opt , "-storehistory" , 1 );
 
opt = optimbase_histset ( opt , 1 , "-xopt" , [1.0 1.0]' );
 
x0 = optimbase_histget ( opt , 1 , "-xopt" );
 
assert_close ( x0 , [1.0 1.0]', %eps );
 
// Check history storing with fopt
 
opt = optimbase_configure ( opt , "-storehistory" , 1 );
 
opt = optimbase_histset ( opt , 1 , "-fopt" , 1.0 );
 
f0 = optimbase_histget ( opt , 1 , "-fopt" );
 
assert_close ( f0 , 1.0, %eps );
 
// Check display
 
optimbase_display ( opt );
Optimization Object

Verbose logging : 0

Verbose Termination : 0

Store History : 1

Number of variables : 2

Initial Guess :

 
  - 1.2  
    1.   
Initial Function Value :0.000000e+000

Optimum Parameters :

 
    1.    1.  
Optimum Function Value :1.000000e+000

Number of iterations : 1

Maximum number of iterations : 200

Number function evaluations : 0

Maximum number of function evaluations : 200

Termination Method on function value : disabled

Termination Absolute Tolerance on function value : 0

Termination Relative Tolerance on function value : 2.220D-15

Termination Method on x : enabled

Termination Absolute Tolerance on x : 0

Termination Relative Tolerance on x : 2.220D-15

Optimization Status : maxiter

 
// Check the boundsmin, boundsmax and nbineqconst
 
opt = optimbase_configure ( opt , "-boundsmin" , [-5.0 -5.0] );
 
boundsmin = optimbase_cget ( opt , "-boundsmin" );
 
assert_equal ( boundsmin , [-5.0 -5.0] );
 
opt = optimbase_configure ( opt , "-boundsmax" , [5.0 5.0] );
 
boundsmax = optimbase_cget ( opt , "-boundsmax" );
 
assert_equal ( boundsmax , [5.0 5.0] );
 
opt = optimbase_configure ( opt , "-nbineqconst" , 3 );
 
nbineqconst = optimbase_cget ( opt , "-nbineqconst" );
 
assert_equal ( nbineqconst , 3 );
 
// Cleanup
 
opt = optimbase_destroy(opt);
 
 
 
// Scilab ( http://www.scilab.org/ ) - This file is part of Scilab
 
// Copyright (C) 2008-2009 - INRIA - Michael Baudin
 
//
 
// This file must be used under the terms of the CeCILL.
 
// This source file is licensed as described in the file COPYING, which
 
// you should have received as part of this distribution.  The terms
 
// are also available at
 
// http://www.cecill.info/licences/Licence_CeCILL_V2-en.txt
 
 
 
//
 
// assert_close --
 
//   Returns 1 if the two real matrices computed and expected are close,
 
//   i.e. if the relative distance between computed and expected is lesser than epsilon.
 
// Arguments
 
//   computed, expected : the two matrices to compare
 
//   epsilon : a small number
 
//
 
function flag = assert_close ( computed, expected, epsilon )
  if expected==0.0 then
    shift = norm(computed-expected);
  else
    shift = norm(computed-expected)/norm(expected);
  end
  if shift < epsilon then
    flag = 1;
  else
    flag = 0;
  end
  if flag <> 1 then pause,end
endfunction
 
//
 
// assert_equal --
 
//   Returns 1 if the two real matrices computed and expected are equal.
 
// Arguments
 
//   computed, expected : the two matrices to compare
 
//   epsilon : a small number
 
//
 
function flag = assert_equal ( computed , expected )
  if computed==expected then
    flag = 1;
  else
    flag = 0;
  end
  if flag <> 1 then pause,end
endfunction
 
//
 
// Test proj2bnds method
 
//
 
//
 
// Test with bounds
 
//
 
opt = optimbase_new ();
 
opt = optimbase_configure(opt,"-numberofvariables",2);
 
opt = optimbase_configure(opt,"-verbose",1);
 
opt = optimbase_configure ( opt , "-boundsmin" , [-5.0 -5.0] );
 
opt = optimbase_configure ( opt , "-boundsmax" , [5.0 5.0] );
 
[ opt , p ] = optimbase_proj2bnds ( opt ,  [0.0 0.0] );
 
assert_equal ( p , [0.0 0.0] );
 
[ opt , p ] = optimbase_proj2bnds ( opt ,  [-6.0 6.0] );
Projecting p(1) = -6.000000e+000 on min bound -5.000000e+000

Projecting p(2) = 6.000000e+000 on max bound 5.000000e+000

 
assert_equal ( p , [-5.0 5.0] );
 
opt = optimbase_destroy(opt);
 
//
 
// Test without bounds
 
//
 
opt = optimbase_new ();
 
opt = optimbase_configure(opt,"-numberofvariables",2);
 
opt = optimbase_configure(opt,"-verbose",1);
 
[ opt , p ] = optimbase_proj2bnds ( opt ,  [0.0 0.0] );
 
assert_equal ( p , [0.0 0.0] );
 
opt = optimbase_destroy(opt);
 
 
